{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdeOc6XgfGa8"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- TTS\n",
    "- cutlet\n",
    "- unidic\n",
    "- SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dupSyK2YfNAX",
    "outputId": "73358dff-907e-4f6b-d8e6-e83d2bf1c2b1"
   },
   "outputs": [],
   "source": [
    "pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBCuiWdSvK2O",
    "outputId": "5ff5b04c-19b2-422a-ed60-48143041106c"
   },
   "outputs": [],
   "source": [
    "pip install TTS[ja]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "a3_uyO-Eiur8",
    "outputId": "696455ee-514b-47a3-b455-aba896aa5311"
   },
   "outputs": [],
   "source": [
    "pip install cutlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaImABV0jaGQ",
    "outputId": "cbd09dc5-3341-4d9a-a7f7-00832dcb5469"
   },
   "outputs": [],
   "source": [
    "pip install 'fugashi[unidic]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDAc9OH4vBvx",
    "outputId": "66a34eb1-f855-4182-ffa3-7fa7918dca6a"
   },
   "outputs": [],
   "source": [
    "!python -m unidic download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqVTNgYqrSGf",
    "outputId": "035c1b0a-713c-4800-fbb3-440e640e06fd"
   },
   "outputs": [],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VvPcJpzf43_"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KfpXPbZwf74r"
   },
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import torch\n",
    "import cutlet\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bliNZHzgm2Y"
   },
   "source": [
    "# TTS (Coqui)\n",
    "\n",
    "Github ref: https://github.com/coqui-ai/TTS?tab=readme-ov-file\n",
    "\n",
    "Models: https://github.com/coqui-ai/TTS/blob/dev/TTS/.models.json\n",
    "\n",
    "I'm currently using multilingual multi-dataset. I'd recommend we finetune the model before using it to production because some phrases are not that clear or sound robotic. Some tasks I will still do:\n",
    "\n",
    "- [ ] Find a voice database in english (probably I'll stick to mitsuru_kirijo or some RPG/famous movie voice)\n",
    "- [ ] Find a voice database in portuguese and japanese\n",
    "- [ ] Test other models for testing computation run time (currently 40s)\n",
    "- [ ] Train/finetune the choosen model (optional: is it worth to train an F5-tts?)\n",
    "- [ ] Make this an API (colab is just to prototyping quickly)\n",
    "\n",
    "Notes:\n",
    "- english works just fine, but sometimes it makes some mistakes\n",
    "- japanese sometimes is not really smooth here I think is due to the reference audio I provided, maybe using a better sample will solve it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7NgLMW9vEyK",
    "outputId": "31d4762b-7528-4ef4-f35d-23e78aeda87a"
   },
   "outputs": [],
   "source": [
    "# This should be in the initialize() and the variables must be globally declared\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available 🐸 TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init 🐸 TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Currently available languages list\n",
    "languages = {\"en\": \"English\", \"ja\": \"Japanese\", \"pt\": \"Portuguese\"}\n",
    "\n",
    "# Change the japanese reference audio later (this sample is simply awful haha)\n",
    "reference_audio_paths = {\"en\": \"./mitsuru_kirijo_01.wav\", \"ja\": \"./bocchi_noisesV4.wav\"}\n",
    "\n",
    "# Speech Recognition\n",
    "# API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "# obtain audio from the wav file\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# OpenAI not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X5M_8flOwCOL"
   },
   "outputs": [],
   "source": [
    "# Choose language\n",
    "lang = \"en\"\n",
    "\n",
    "text = \"The greatest joy of magic lies in searching for it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEX7AjYYgrBQ",
    "outputId": "54042b6b-983c-475c-acd7-2d51f7bd24ac"
   },
   "outputs": [],
   "source": [
    "# This should be a route\n",
    "\n",
    "def textToSpeech(text, lang):\n",
    "  # Error handling\n",
    "  if lang not in languages.keys():\n",
    "      print(\"Language not supported\")\n",
    "      exit()\n",
    "\n",
    "  # Generate TTS with voice cloning\n",
    "  tts.tts_to_file(text=text, speaker_wav=reference_audio_paths[lang], file_path=\"test.wav\", language = lang)\n",
    "  return\n",
    "\n",
    "# test\n",
    "textToSpeech(text, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oni901w9oM-J"
   },
   "source": [
    "# STT\n",
    "It worked haha prob we'll need a Google API Key for production but I think STT won't be a short term bottleneck.\n",
    "\n",
    "Next step is to get this text, send to OpenAI and generate a prompt-based answer to be send to TTS. Once this is achieved, we'll have a really basic SST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lCEvzbHcrJd9",
    "outputId": "1cab9d53-13df-40df-fb8c-64fbc8eea42d"
   },
   "outputs": [],
   "source": [
    "# This should be another route\n",
    "\n",
    "def speechToText(lang, audio):\n",
    "  # Need to implement lang and mapping to the correct format (en -> en-US ...)\n",
    "  # For now, only english is available or any other hardcoded lang (already tested japanese -> ja-JP and it works smoothly)\n",
    "  with sr.AudioFile(f\"{audio}.wav\") as source:\n",
    "      audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "  # recognize speech using Google Speech Recognition\n",
    "  try:\n",
    "      # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "      # instead of `r.recognize_google(audio)`\n",
    "      print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio, language=\"en-US\"))\n",
    "      return r.recognize_google(audio, language=\"en-US\")\n",
    "  except sr.UnknownValueError:\n",
    "      print(\"Google Speech Recognition could not understand audio\")\n",
    "  except sr.RequestError as e:\n",
    "      print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "# test\n",
    "test_text = speechToText(\"en\", \"test\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xdeOc6XgfGa8",
    "2VvPcJpzf43_",
    "1bliNZHzgm2Y",
    "oni901w9oM-J"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
